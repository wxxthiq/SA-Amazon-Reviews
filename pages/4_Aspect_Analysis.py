# pages/4_Aspect_Analysis.py
import streamlit as st
import pandas as pd
import spacy
from collections import Counter
import re
from textblob import TextBlob
from utils.database_utils import (
    connect_to_db,
    get_product_details,
    get_reviews_for_product,
    get_product_date_range
)

# --- Page Configuration and NLP Model Loading ---
st.set_page_config(layout="wide", page_title="Aspect Analysis")

@st.cache_resource
def load_spacy_model():
    return spacy.load("en_core_web_sm")

nlp = load_spacy_model()
DB_PATH = "amazon_reviews_top100.duckdb"
conn = connect_to_db(DB_PATH)

# --- Main App Logic ---
def main():
    st.title("ðŸ”Ž Automated Aspect Analysis")

    if st.button("â¬…ï¸ Back to Sentiment Overview"):
        st.switch_page("pages/1_Sentiment_Overview.py")

    # (Code for product loading and sidebar filters is unchanged)
    # ...
    if 'selected_product' not in st.session_state or st.session_state.selected_product is None:
        st.warning("Please select a product from the main search page first.")
        st.stop()
    selected_asin = st.session_state.selected_product
    product_details = get_product_details(conn, selected_asin).iloc[0]
    st.header(product_details['product_title'])
    st.caption("This page automatically identifies the most talked-about features (aspects) in the reviews.")
    st.sidebar.header("ðŸ”¬ Aspect Analysis Filters")
    min_date_db, max_date_db = get_product_date_range(conn, selected_asin)
    default_date_range = (min_date_db, max_date_db)
    default_ratings = [1, 2, 3, 4, 5]
    default_verified = "All"
    selected_date_range = st.sidebar.date_input("Filter by Date Range", value=default_date_range, key='aspect_date_filter')
    selected_ratings = st.sidebar.multiselect("Filter by Star Rating", options=default_ratings, default=default_ratings, key='aspect_rating_filter')
    selected_verified = st.sidebar.radio("Filter by Purchase Status", ["All", "Verified Only", "Not Verified"], index=0, key='aspect_verified_filter')
    chart_data = get_reviews_for_product(conn, selected_asin, selected_date_range, tuple(selected_ratings), ['Positive', 'Negative', 'Neutral'], selected_verified)
    st.markdown("---")
    if chart_data.empty:
        st.warning("No review data available for the selected filters.")
        st.stop()
    st.info(f"Analyzing aspects from **{len(chart_data)}** reviews matching your criteria.")

    # --- AUTOMATED ASPECT EXTRACTION (WITH NOUN CHUNKING) ---
    @st.cache_data
    def extract_top_aspects_with_chunks(texts, top_n=20):
        # ** KEY CHANGE: Use noun chunks to find multi-word aspects **
        all_aspects = []
        for doc in nlp.pipe(texts, disable=["parser", "ner"]):
            for chunk in doc.noun_chunks:
                # Filter for more meaningful chunks
                if len(chunk.text.split()) > 1 or chunk.root.pos_ == 'PROPN':
                    all_aspects.append(chunk.lemma_.lower())
        
        return [aspect for aspect, freq in Counter(all_aspects).most_common(top_n)]

    with st.spinner("Automatically identifying key aspects from reviews..."):
        top_aspects = extract_top_aspects_with_chunks(chart_data['text'].astype(str))

    st.markdown("### ðŸ”¬ Interactive Aspect Explorer")
    selected_aspect = st.selectbox(
        "Select an auto-detected aspect to analyze:",
        options=["--- Select an Aspect ---"] + top_aspects
    )

    if selected_aspect != "--- Select an Aspect ---":
        # (The rest of the analysis and display logic is unchanged)
        # ...
        @st.cache_data
        def calculate_aspect_sentiments(data, aspect, window=10):
            sentiments = []
            snippets = []
            for index, row in data.iterrows():
                text = str(row['text']).lower()
                if re.search(r'\b' + re.escape(aspect) + r'\b', text):
                    for match in re.finditer(r'\b' + re.escape(aspect) + r'\b', text):
                        start, end = match.start(), match.end()
                        words_before = text[:start].split()[-window:]
                        words_after = text[end:].split()[:window]
                        context_text = " ".join(words_before + [aspect] + words_after)
                        sentiment = TextBlob(context_text).sentiment.polarity
                        sentiments.append(sentiment)
                        highlighted_snippet = " ".join(words_before) + f" **:orange[{aspect}]** " + " ".join(words_after)
                        snippets.append((row['review_id'], highlighted_snippet, row['rating'], row['helpful_vote']))
            return sentiments, snippets
        aspect_sentiments, aspect_snippets = calculate_aspect_sentiments(chart_data, selected_aspect)
        st.markdown(f"---")
        st.markdown(f"#### Analysis for aspect: `{selected_aspect}` ({len(aspect_sentiments)} mentions)")
        if not aspect_sentiments:
            st.warning(f"No mentions of the aspect '{selected_aspect}' found in the filtered reviews.")
        else:
            sentiment_df = pd.DataFrame(aspect_sentiments, columns=['polarity'])
            sentiment_df['sentiment_category'] = sentiment_df['polarity'].apply(lambda p: 'Positive' if p > 0.1 else ('Negative' if p < -0.1 else 'Neutral'))
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**Aspect Sentiment Distribution**")
                dist = sentiment_df['sentiment_category'].value_counts().reindex(['Positive', 'Neutral', 'Negative'], fill_value=0)
                st.bar_chart(dist)
            with col2:
                st.markdown("**Sentiment Polarity Trend**")
                st.line_chart(sentiment_df['polarity'])
            st.markdown(f"**Example mentions of `{selected_aspect}`**")
            sorted_snippets = sorted(aspect_snippets, key=lambda x: x[3], reverse=True)
            for review_id, snippet, rating, helpful_votes in sorted_snippets[:10]:
                with st.container(border=True):
                    st.caption(f"From a {rating} â­ review ({helpful_votes} helpful votes)")
                    st.markdown(f"...{snippet}...")

if __name__ == "__main__":
    main()
